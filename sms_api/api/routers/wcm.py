"""
[x] base sim (cached)
- antibiotic
- biomanufacturing
- batch variant endpoint
- design specific endpoints.
- downsampling ...
- biocyc id
- api to download the data
- marimo instead of Jupyter notebooks....(auth). ... also on gov cloud.
- endpoint to send sql like queries to parquet files back to client

[x] (/simulation/analysis/download)[exp_id, analysis_id, start, stop, n_windows(cols in tsv)] <- downloads any whose
     generation was configured by <CONFIG>.json

[ ] (/simulation/results/download)[exp_id, observables, n_timesteps] <- downloads parquet files (if any)
    generated by the ParquetEmitter during simulation

[ ] (/simulation/state/download)[exp_id, observables, n_timesteps] <- downloads any .json files whose generation
    was configured by enabling the "save" option in simulation (save times)

[ ] (/simulation/state)[exp_id, observables, n_timesteps] <- get serialized JSON of any .json files whose generation
    was configured by enabling the "save" option in simulation (save times)

***We should implement the /download... endpoint for each router as
    this is a way to easily configure filepaths as they pertain to
    hive partitioning: single simulations will always have the same hive partitioning, etc.
"""

import logging
from pathlib import Path
from typing import Optional

from fastapi import APIRouter, BackgroundTasks, Depends, HTTPException, Query
from fastapi.responses import FileResponse

# from sms_api.api.request_examples import examples
from sms_api.common.gateway.io import get_zip_buffer, write_zip_buffer
from sms_api.common.gateway.models import RouterConfig, ServerMode
from sms_api.common.gateway.utils import REPO_DIR, get_simulator
from sms_api.config import get_settings
from sms_api.data.parquet_service import ParquetService
from sms_api.dependencies import (
    get_database_service,
    get_simulation_service,
)
from sms_api.simulation.handlers import run_workflow
from sms_api.simulation.hpc_utils import read_latest_commit
from sms_api.simulation.models import (
    EcoliExperiment,
    EcoliSimulation,
    EcoliWorkflowRequest,
    HpcRun,
    JobType,
    Overrides,
    SimulatorVersion,
    Variants,
)

logger = logging.getLogger(__name__)

LATEST_COMMIT = read_latest_commit()
ROUTER_TAG = ["Simulations - vEcoli"]


def get_server_url(dev: bool = True) -> ServerMode:
    return ServerMode.DEV if dev else ServerMode.PROD


config = RouterConfig(router=APIRouter(), prefix="/wcm", dependencies=[])


@config.router.get(path="/simulation/configs", operation_id="get-available-configs", tags=["Simulations - vEcoli"])
async def get_available_config_ids(simulator_hash: str | None = Query(default=None)) -> list[str]:
    fname = "available_configs.txt"
    print(simulator_hash)
    env = get_settings()
    path = Path(f"{env.slurm_base_path}/prod") / fname  # currently 78c6310 (8/22/25)
    if not path.exists():
        path = Path(f"{REPO_DIR}/assets/simulation") / fname
    with open(path) as fp:
        available = [lin.strip().replace(".json", "") for lin in fp.readlines()]
    return available


@config.router.post(
    path="/simulation/run",
    operation_id="run-simulation-workflow",
    response_model=EcoliExperiment,
    tags=["Simulations - vEcoli"],
    dependencies=[Depends(get_simulation_service), Depends(get_database_service)],
    summary="Dispatches a nextflow-powered vEcoli simulation workflow",
)
async def run_simulation_workflow(
    background_tasks: BackgroundTasks,
    config_id: str = Query(default="sms_single"),
    overrides: Optional[Overrides] = None,
    variants: Optional[Variants] = None,
    # max_duration: float = Query(default=10800.0),
    # time_step: float = Query(default=1.0),
) -> EcoliExperiment:
    simulator: SimulatorVersion = get_simulator()
    sim_request = EcoliWorkflowRequest(config_id=config_id, overrides=overrides, variants=variants, simulator=simulator)
    sim_service = get_simulation_service()
    if sim_service is None:
        logger.error("Simulation service is not initialized")
        raise HTTPException(status_code=500, detail="Simulation service is not initialized")
    db_service = get_database_service()
    if db_service is None:
        logger.error("Database service is not initialized")
        raise HTTPException(status_code=500, detail="Database service is not initialized")

    try:
        return await run_workflow(
            simulation_request=sim_request,
            simulation_service_slurm=sim_service,
            background_tasks=background_tasks,
            # database_service=db_service,
        )
    except Exception as e:
        logger.exception("Error running vEcoli simulation")
        raise HTTPException(status_code=500, detail=str(e)) from e
    return [simulator, sim_request]


@config.router.post(
    path="/data",
    response_class=FileResponse,
    operation_id="get-data",
    tags=["Data - vEcoli"],
    summary="Get simulation outputs",
)
async def get_results(
    background_tasks: BackgroundTasks,
    experiment_id: str = Query(
        examples=["sms_single"], description="Experiment ID for the simulation (from config.json)."
    ),
    filename: str | None = Query(default=None, description="Name you wish to assign to the downloaded zip file"),
) -> FileResponse:
    try:
        service = ParquetService()
        pq_dir = service.get_parquet_dir(experiment_id)
        buffer = get_zip_buffer(pq_dir)
        fname = filename or experiment_id
        filepath = write_zip_buffer(buffer, fname, background_tasks)

        return FileResponse(path=filepath, media_type="application/octet-stream", filename=filepath.name)
    except Exception as e:
        logger.exception("Error fetching the simulation analysis file.")
        raise HTTPException(status_code=500, detail=str(e)) from e


@config.router.get(
    path="/simulation/versions",
    response_model=list[EcoliSimulation],
    operation_id="get-workflow-versions",
    tags=["Simulations - vEcoli"],
    summary="Get list of vEcoli simulations",
)
async def get_workflow_versions() -> list[EcoliSimulation]:
    db_service = get_database_service()
    if db_service is None:
        logger.error("Simulation database service is not initialized")
        raise HTTPException(status_code=500, detail="Simulation database service is not initialized")

    try:
        simulations: list[EcoliSimulation] = await db_service.list_simulations()
        return simulations
    except Exception as e:
        logger.exception("Error getting simulations")
        raise HTTPException(status_code=500, detail=str(e)) from e


@config.router.get(
    path="/simulation/status",
    response_model=HpcRun,
    operation_id="get-workflow-status",
    tags=["Simulations - vEcoli"],
    dependencies=[Depends(get_database_service)],
    summary="Get the simulation status record by its ID",
)
async def get_simulation_status(
    simulation_id: int = Query(...), num_events: int | None = Query(default=None)
) -> HpcRun:
    db_service = get_database_service()
    if db_service is None:
        logger.error("SSH service is not initialized")
        raise HTTPException(status_code=500, detail="SSH service is not initialized")
    # experiment_dir = Path("/home/FCAM/svc_vivarium/test/sims/experiment_96bb7a2_id_1_20250620-181422")
    try:
        simulation_hpcrun: HpcRun | None = await db_service.get_hpcrun_by_ref(
            ref_id=simulation_id, job_type=JobType.SIMULATION
        )
    except Exception as e:
        logger.exception(f"Error fetching simulation results for simulation id: {simulation_id}.")
        raise HTTPException(status_code=500, detail=str(e)) from e

    if simulation_hpcrun is None:
        raise HTTPException(status_code=404, detail=f"Simulation with id {simulation_id} not found.")
    return simulation_hpcrun


# @config.router.post(
#     path="/parameters",
#     operation_id="get-wcm-parameters",
#     response_model=SimulationParameters,
#     tags=["Data - vEcoli"],
#     dependencies=[Depends(get_simulation_service), Depends(get_database_service)],
# )
# async def get_wcm_parameters(experiment_id: str = Query(...)) -> list[str]:
#     return [f'WCM Parameters according to {experiment_id}']
