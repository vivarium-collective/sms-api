"""
[x] base sim (cached)
- antibiotic
- biomanufacturing
- batch variant endpoint
- design specific endpoints.
- downsampling ...
- biocyc id
- api to download the data
- marimo instead of Jupyter notebooks....(auth). ... also on gov cloud.
- endpoint to send sql like queries to parquet files back to client

[x] (/simulation/analysis/download)[exp_id, analysis_id, start, stop, n_windows(cols in tsv)] <- downloads any whose
     generation was configured by <CONFIG>.json

[ ] (/simulation/results/download)[exp_id, observables, n_timesteps] <- downloads parquet files (if any)
    generated by the ParquetEmitter during simulation

[ ] (/simulation/state/download)[exp_id, observables, n_timesteps] <- downloads any .json files whose generation
    was configured by enabling the "save" option in simulation (save times)

[ ] (/simulation/state)[exp_id, observables, n_timesteps] <- get serialized JSON of any .json files whose generation
    was configured by enabling the "save" option in simulation (save times)

***We should implement the /download... endpoint for each router as
    this is a way to easily configure filepaths as they pertain to
    hive partitioning: single simulations will always have the same hive partitioning, etc.
"""

import json
import logging
import mimetypes
import os
import tempfile
import uuid
from collections.abc import Generator
from io import BytesIO
from pathlib import Path
from typing import Any, Optional, Union
from zipfile import ZIP_DEFLATED, ZipFile

from fastapi import APIRouter, BackgroundTasks, Depends, HTTPException, Query
from fastapi.responses import FileResponse, HTMLResponse, StreamingResponse
from pydantic import BaseModel

from sms_api.common.gateway.io import get_zip_buffer, write_zip_buffer
from sms_api.common.gateway.models import RouterConfig, ServerMode
from sms_api.common.gateway.utils import REPO_DIR, get_simulator
from sms_api.common.ssh.ssh_service import get_ssh_service
from sms_api.config import get_settings

# from sms_api.api.request_examples import examples
from sms_api.data.analysis_service import AnalysisService
from sms_api.data.parquet_service import ParquetService
from sms_api.dependencies import (
    get_database_service,
    get_simulation_service,
)
from sms_api.simulation.handlers import run_workflow
from sms_api.simulation.hpc_utils import read_latest_commit
from sms_api.simulation.models import (
    EcoliExperiment,
    EcoliSimulation,
    EcoliWorkflowRequest,
    JobStatus,
    Overrides,
    SimulationConfig,
    SimulationRun,
    SimulatorVersion,
    Variants,
)

logger = logging.getLogger(__name__)

LATEST_COMMIT = read_latest_commit()
ROUTER_TAG = ["Simulations - vEcoli"]

config = RouterConfig(router=APIRouter(), prefix="/wcm", dependencies=[])


def get_server_url(dev: bool = True) -> ServerMode:
    return ServerMode.DEV if dev else ServerMode.PROD


def get_experiment_id_from_tag(experiment_tag: str) -> str:
    parts = experiment_tag.split("-")
    parts.remove(parts[-1])
    return "-".join(parts)


def get_analysis_dir(outdir: Path, experiment_id: str) -> Path:
    return outdir / experiment_id / "analyses"


def get_analysis_paths(analysis_dir: Path) -> set[Path]:
    paths = set()
    for root, _, files in analysis_dir.walk():
        for fname in files:
            fp = root / fname
            if fp.exists():
                paths.add(fp)
    return paths


def generate_zip(file_paths: list[tuple[Path, str]]) -> Generator[Any]:
    """
    Generator function to stream a zip file dynamically.
    """
    # Use BytesIO as an in-memory file-like object for chunks
    buffer = BytesIO()
    with ZipFile(buffer, "w", ZIP_DEFLATED) as zip_file:
        for file_path, arcname in file_paths:
            # arcname is the filename inside the zip (can handle non-unique names)
            zip_file.write(file_path, arcname=arcname)
    buffer.seek(0)
    yield from buffer


@config.router.get(path="/simulation/configs", operation_id="get-available-configs", tags=["Simulations - vEcoli"])
async def get_available_config_ids(simulator_hash: str | None = Query(default=None)) -> list[str]:
    fname = "available_configs.txt"
    print(simulator_hash)
    env = get_settings()
    path = Path(f"{env.slurm_base_path}/prod") / fname  # currently 78c6310 (8/22/25)
    if not path.exists():
        path = Path(f"{REPO_DIR}/assets/simulation") / fname
    with open(path) as fp:
        available = [lin.strip().replace(".json", "") for lin in fp.readlines()]
    return available


@config.router.post(
    path="/simulation/run",
    operation_id="run-simulation-workflow",
    response_model=EcoliExperiment,
    tags=["Simulations - vEcoli"],
    dependencies=[Depends(get_simulation_service), Depends(get_database_service)],
    summary="Dispatches a nextflow-powered vEcoli simulation workflow",
)
async def run_simulation_workflow(
    background_tasks: BackgroundTasks,
    config_id: Optional[str] = None,
    overrides: Optional[Overrides] = None,
    variants: Optional[Variants] = None,
    config: SimulationConfig | None = None,
    # max_duration: float = Query(default=10800.0),
    # time_step: float = Query(default=1.0),
) -> EcoliExperiment:
    simulator: SimulatorVersion = get_simulator()
    if config is not None:
        env = get_settings()
        ssh = get_ssh_service(env)
        serialized = config.to_json()
        config_id = serialized.get("experiment_id", f"experiment-{uuid.uuid4()}")
        with tempfile.TemporaryDirectory() as dirname:
            local = Path(f"{dirname}/{config_id}.json")
            with open(local, "w") as fp:
                json.dump(serialized, fp, indent=3)
            remote = Path(env.slurm_base_path) / "workspace" / "vEcoli" / "configs" / local.parts[-1]
            await ssh.scp_upload(local_file=local, remote_path=remote)

    sim_request = EcoliWorkflowRequest(
        config_id=config_id or "sms_single", overrides=overrides, variants=variants, simulator=simulator
    )
    sim_service = get_simulation_service()
    if sim_service is None:
        logger.error("Simulation service is not initialized")
        raise HTTPException(status_code=500, detail="Simulation service is not initialized")
    db_service = get_database_service()
    if db_service is None:
        logger.error("Database service is not initialized")
        raise HTTPException(status_code=500, detail="Database service is not initialized")

    try:
        return await run_workflow(
            simulation_request=sim_request,
            simulation_service_slurm=sim_service,
            # background_tasks=background_tasks,
            # database_service=db_service,
        )
    except Exception as e:
        logger.exception("Error running vEcoli simulation")
        raise HTTPException(status_code=500, detail=str(e)) from e


@config.router.get(
    path="/simulation/run/status",
    response_model=SimulationRun,
    operation_id="get-vecoli-simulation-status",
    tags=["Simulations - vEcoli"],
    dependencies=[Depends(get_database_service)],
    summary="Get the simulation status record by its ID",
)
async def get_simulation_status(experiment_tag: str = Query(...)) -> SimulationRun:
    env = get_settings()
    try:
        slurmjob_id = experiment_tag.split("-")[-1]
        # slurmjob_id = get_jobid_by_experiment(experiment_id)
        ssh_service = get_ssh_service()
        slurm_user = env.slurm_submit_user
        statuses = await ssh_service.run_command(f"sacct -u {slurm_user} | grep {slurmjob_id}")
        status = statuses[1].split("\n")[0].split()[-2]
        return SimulationRun(id=experiment_tag, status=JobStatus[status])
    except Exception as e:
        logger.exception(
            """Error getting simulation status.\
                Are you sure that you've passed the experiment_tag? (not the experiment id)
            """
        )
        raise HTTPException(status_code=500, detail=str(e)) from e


@config.router.post(
    path="/simulation/run/log",
    operation_id="get-vecoli-simulation-log",
    tags=["Simulations - vEcoli"],
    summary="Get the simulation log record of a given experiment",
)
async def get_simulation_log(experiment: EcoliExperiment) -> str:
    env = get_settings()
    try:
        # slurmjob_id = get_jobid_by_experiment(experiment_id)
        ssh_service = get_ssh_service()
        # slurm_user = env.slurm_submit_user
        returncode, stdout, stderr = await ssh_service.run_command(
            f"cat {env.slurm_base_path!s}/prod/htclogs/{experiment.experiment_id}.out"
        )
        return stdout
    except Exception as e:
        logger.exception("""Error getting simulation log.""")
        raise HTTPException(status_code=500, detail=str(e)) from e


class AnalysisOutput(BaseModel):
    id: str
    files: list[str]


class Analyses(BaseModel):
    value: list[AnalysisOutput]


@config.router.get(
    path="/analysis/outputs",
    response_model=None,
    operation_id="get-available-analyses",
    tags=["Data - vEcoli"],
    summary="Get all available analyses for a given simulation",
)
async def get_available_analyses(experiment_id: str = Query(...)) -> dict[str, list[str]]:
    try:
        env = get_settings()
        service = AnalysisService()
        outdir = Path(env.simulation_outdir)
        # experiment_id = get_experiment_id_from_tag(experiment_tag)
        analysis_dir = service.get_analysis_dir(outdir, experiment_id)
        paths = service.get_analysis_paths(analysis_dir)
        manifest_template = service.get_manifest_template(paths)
        manifest = service.get_manifest(analysis_paths=paths, template=manifest_template)

        # analyses = Analyses(
        #     value=[
        #         AnalysisOutput(id=k, files=v)
        #         for k, v in manifest.items()
        #     ]
        # )
        # return analyses
        return manifest
    except Exception as e:
        logger.exception("Error fetching the simulation analysis file.")
        raise HTTPException(status_code=500, detail=str(e)) from e


@config.router.get(
    path="/analysis/download",
    response_model=None,
    # response_class=FileResponse,
    operation_id="download-analysis-output",
    tags=["Data - vEcoli"],
    summary="Download a file that was generated from a simulation analysis module",
)
async def download_analysis_file(
    experiment_id: str = Query(...),
    variant_id: int = Query(default=0),
    lineage_seed_id: int = Query(default=0),
    generation_id: int = Query(default=1),
    agent_id: int = Query(default=0),
    filename: str = Query(examples=["mass_fraction_summary.html"]),
) -> Union[FileResponse, HTMLResponse]:
    try:
        env = get_settings()
        # experiment_id = get_experiment_id_from_tag(experiment_tag)
        # filepath = service.get_file_path(experiment_id, filename, remote=True, logger_instance=logger)
        filepath = (
            Path(env.simulation_outdir)
            / experiment_id
            / "analyses"
            / f"variant={variant_id}"
            / f"lineage_seed={lineage_seed_id}"
            / f"generation={generation_id}"
            / f"agent_id={agent_id}"
            / "plots"
            / filename
        )
        mimetype, _ = mimetypes.guess_type(filepath)

        if str(filepath).endswith(".html"):
            return HTMLResponse(content=filepath.read_text(encoding="utf-8"))
        return FileResponse(path=filepath, media_type=mimetype or "application/octet-stream", filename=filepath.name)
    except Exception as e:
        logger.exception("Error fetching the simulation analysis file.")
        raise HTTPException(status_code=500, detail=str(e)) from e


@config.router.get(
    path="/analysis/results",
    response_model=None,
    # response_class=FileResponse,
    operation_id="download-analysis-results",
    tags=["Data - vEcoli"],
    summary="Download a file that was generated from a simulation analysis module",
)
async def download_analysis(
    experiment_id: str = Query(...),
    variant_id: int = Query(default=0),
    lineage_seed_id: int = Query(default=0),
    generation_id: int = Query(default=1),
    agent_id: int = Query(default=0),
    filename: str = Query(examples=["mass_fraction_summary.html"]),
) -> Union[FileResponse, HTMLResponse]:
    try:
        env = get_settings()
        # experiment_id = get_experiment_id_from_tag(experiment_tag)
        # filepath = service.get_file_path(experiment_id, filename, remote=True, logger_instance=logger)
        filepath = (
            Path(env.simulation_outdir)
            / experiment_id
            / "analyses"
            / f"variant={variant_id}"
            / f"lineage_seed={lineage_seed_id}"
            / f"generation={generation_id}"
            / f"agent_id={agent_id}"
            / "plots"
            / filename
        )
        mimetype, _ = mimetypes.guess_type(filepath)

        if str(filepath).endswith(".html"):
            return HTMLResponse(content=filepath.read_text(encoding="utf-8"))
        return FileResponse(path=filepath, media_type=mimetype or "application/octet-stream", filename=filepath.name)
    except Exception as e:
        logger.exception("Error fetching the simulation analysis file.")
        raise HTTPException(status_code=500, detail=str(e)) from e


@config.router.get(
    path="/analyses/download",
    response_class=StreamingResponse,
    operation_id="download-analyses",
    tags=["Data - vEcoli"],
    description="Download all available simulation analysis outputs as a .zip file",
)
async def download_analyses(
    # experiment: EcoliExperiment,
    experiment_id: str = Query(...),
) -> StreamingResponse:
    try:
        # outdir = Path("/Users/alexanderpatrie/sms/vEcoli/out")
        # experiment_id = "sms_multiseed"
        settings = get_settings()
        outdir = Path(settings.slurm_base_path) / "workspace" / "outputs"
        # experiment_id = get_experiment_id_from_tag(experiment_tag)
        analysis_dir = get_analysis_dir(outdir=outdir, experiment_id=experiment_id)

        file_paths = []
        for root, _, files in analysis_dir.walk():
            for f in files:
                fp = root / f
                abs_path = fp.absolute()
                arcname = os.path.relpath(str(abs_path), analysis_dir)
                file_paths.append((abs_path, arcname))

        return StreamingResponse(
            generate_zip(file_paths),
            media_type="application/x-zip-compressed",
            headers={"Content-Disposition": f"attachment; filename={experiment_id}.zip"},
        )
    except Exception as e:
        logger.exception("Error fetching the simulation analysis files.")
        raise HTTPException(status_code=500, detail=str(e)) from e


@config.router.post(
    path="/data",
    response_class=FileResponse,
    operation_id="get-data",
    tags=["Data - vEcoli"],
    summary="Get simulation outputs",
)
async def get_results(
    background_tasks: BackgroundTasks,
    experiment_id: str = Query(..., description="Experiment id for the simulation."),
    # experiment: EcoliExperiment,
    variant_id: int = Query(default=0),
    lineage_seed_id: int = Query(default=0),
    generation_id: int = Query(default=1),
    agent_id: int = Query(default=0),
    filename: str | None = Query(default=None, description="Name you wish to assign to the downloaded zip file"),
) -> FileResponse:
    try:
        service = ParquetService()
        # experiment_id = get_experiment_id_from_tag(experiment_tag)
        pq_dir = service.get_parquet_dir(
            experiment_id=experiment_id,
            variant=variant_id,
            lineage_seed=lineage_seed_id,
            generation=generation_id,
            agent_id=agent_id,
        )
        buffer = get_zip_buffer(pq_dir)
        fname = filename or experiment_id
        filepath = write_zip_buffer(buffer, fname, background_tasks)

        # return FileResponse(path=filepath, media_type="application/octet-stream", filename=filepath.name)
        # return str(pq_dir)
        return FileResponse(path=filepath, media_type="application/octet-stream", filename=filepath.name)
    except Exception as e:
        logger.exception("Error fetching the simulation analysis file.")
        raise HTTPException(status_code=500, detail=str(e)) from e


@config.router.get(
    path="/simulation/versions",
    response_model=list[EcoliSimulation],
    operation_id="get-workflow-versions",
    tags=["Simulations - vEcoli"],
    summary="Get list of vEcoli simulations",
)
async def get_workflow_versions() -> list[EcoliSimulation]:
    db_service = get_database_service()
    if db_service is None:
        logger.error("Simulation database service is not initialized")
        raise HTTPException(status_code=500, detail="Simulation database service is not initialized")

    try:
        simulations: list[EcoliSimulation] = await db_service.list_simulations()
        return simulations
    except Exception as e:
        logger.exception("Error getting simulations")
        raise HTTPException(status_code=500, detail=str(e)) from e


# @config.router.post(
#     path="/parameters",
#     operation_id="get-wcm-parameters",
#     response_model=SimulationParameters,
#     tags=["Data - vEcoli"],
#     dependencies=[Depends(get_simulation_service), Depends(get_database_service)],
# )
# async def get_wcm_parameters(experiment_id: str = Query(...)) -> list[str]:
#     return [f'WCM Parameters according to {experiment_id}']
