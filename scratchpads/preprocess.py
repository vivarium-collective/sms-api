# -*- coding: utf-8 -*-
"""preprocessing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vTc9zW2HCMh8T5w-ETIEum6M2_-cfsC3
"""

import numpy as np

data = {"x": {"i": 1, "j": [3, 22, 1111]}, "y": 0.22, "z": {"k": {"a": [1, 2, 3, 4, 5], "b": [1, 2]}}}

# flatten dict such that keys (features) are:
# {
#     x.i
#     x.j
#     y
#     z.k.a
#     z.k.b
# }

from typing import Any, Dict


def flatten_map(d: Dict[str, Any], parent_key: str = "", sep: str = ".") -> Dict[str, Any]:
    items = {}
    for k, v in d.items():
        new_key = f"{parent_key}{sep}{k}" if parent_key else k
        if isinstance(v, dict):
            items.update(flatten_map(v, new_key, sep=sep))
        else:
            items[new_key] = v
    return items


flat = flatten_map(data)
flat

# find the innermost value array that is the longest
# in this case, len(z.k.a) == 5


def get_max(flat):
    items = set()
    for k, v in flat.items():
        if isinstance(v, list):
            items.add((k, len(v)))
    return max([length for name, length in items])


max_length = get_max(flat)
max_length

# pad/normalize val sizes by the max len as other arrays like:
# {
#     x.i: [1, nan, nan, nan, nan],
#     x.j: [3, 22, 11, nan, nan],
#     y: [0.22, nan, nan, nan, nan],
#     z.k.a: [1, 2, 3, 4, 5],
#     z.k.b: [1, 2, nan, nan, nan]
#
# }
#
# a dict whose values() are an array of shape (5, 5) ~> (nfeatures, max_feature_length) as such:
# [[1, nan, nan, nan, nan],
#  [3, 22, 11, nan, nan],
#  [0.22, nan, nan, nan, nan],
#  [1, 2, 3, 4, 5],
#  [1, 2, nan, nan, nan]]


def vectorize_flat(flat):
    normalized = {}
    for k, v in flat.items():
        if not isinstance(v, list):
            normalized[k] = [v]
            for _ in range(max_length - 1):
                normalized[k].append(np.nan)
        else:
            num_short = max_length - len(v)
            for _ in range(abs(num_short)):
                v.append(np.nan)
            normalized[k] = v
    return normalized


vectorized = vectorize_flat(flat)
vectorized

# get just the feature labels

features = list(flat.keys())
features

# flatten the aforementioned dict vals such that you have:
# [1, nan, nan, nan, nan,
#  3, 22, 11, nan, nan,
#  0.22, nan, nan, nan, nan,
#  1, 2, 3, 4, 5,
#  1, 2, nan, nan, nan
# ]

vector = np.array(list(vectorized.values())).flatten()
vector.shape

# handle nan


def handle_nan(vector):
    meanval = np.nanmean(vector)
    return np.where(np.isnan(vector), meanval, vector)


def normalize(x):
    xmin = x.min()
    xmax = x.max()
    return (x - xmin) / (xmax - xmin)


preprocessed = handle_nan(vector)
normalized = normalize(preprocessed)

# be able to hydrate flattened with features


def hydrate(max_length, preprocessed, features):
    data = {}
    nested = preprocessed.reshape(-1, max_length)
    for i, feature in enumerate(features):
        data[feature] = nested[i]
    return data


hydrated = hydrate(max_length, preprocessed, features)
hydrated
