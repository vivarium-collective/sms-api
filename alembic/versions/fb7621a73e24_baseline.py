"""baseline

Revision ID: fb7621a73e24
Revises: 
Create Date: 2025-07-03 16:18:12.274163

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = 'fb7621a73e24'
down_revision: Union[str, Sequence[str], None] = None
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('simulator',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('created_at', sa.DateTime(), server_default=sa.text('now()'), nullable=False),
    sa.Column('git_repo_url', sa.String(), nullable=False),
    sa.Column('git_branch', sa.String(), nullable=False),
    sa.Column('git_commit_hash', sa.String(), nullable=False),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_table('parca_dataset',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('created_at', sa.DateTime(), server_default=sa.text('now()'), nullable=False),
    sa.Column('simulator_id', sa.Integer(), nullable=False),
    sa.Column('parca_config', postgresql.JSONB(astext_type=sa.Text()), nullable=False),
    sa.Column('parca_config_hash', sa.String(), nullable=False),
    sa.Column('remote_archive_path', sa.String(), nullable=True),
    sa.ForeignKeyConstraint(['simulator_id'], ['simulator.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_parca_dataset_simulator_id'), 'parca_dataset', ['simulator_id'], unique=False)
    op.create_table('simulation',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('created_at', sa.DateTime(), server_default=sa.text('now()'), nullable=False),
    sa.Column('simulator_id', sa.Integer(), nullable=False),
    sa.Column('parca_dataset_id', sa.Integer(), nullable=False),
    sa.Column('variant_config', postgresql.JSONB(astext_type=sa.Text()), nullable=False),
    sa.Column('variant_config_hash', sa.String(), nullable=False),
    sa.ForeignKeyConstraint(['parca_dataset_id'], ['parca_dataset.id'], ),
    sa.ForeignKeyConstraint(['simulator_id'], ['simulator.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_simulation_parca_dataset_id'), 'simulation', ['parca_dataset_id'], unique=False)
    op.create_index(op.f('ix_simulation_simulator_id'), 'simulation', ['simulator_id'], unique=False)
    op.create_table('hpcrun',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('created_at', sa.DateTime(), server_default=sa.text('now()'), nullable=False),
    sa.Column('job_type', sa.Enum('SIMULATION', 'PARCA', 'BUILD_IMAGE', name='jobtypedb'), nullable=False),
    sa.Column('slurmjobid', sa.Integer(), nullable=True),
    sa.Column('start_time', sa.DateTime(), nullable=True),
    sa.Column('end_time', sa.DateTime(), nullable=True),
    sa.Column('status', sa.Enum('WAITING', 'QUEUED', 'RUNNING', 'COMPLETED', 'FAILED', name='jobstatusdb'), nullable=False),
    sa.Column('error_message', sa.String(), nullable=True),
    sa.Column('jobref_simulation_id', sa.Integer(), nullable=True),
    sa.Column('jobref_parca_dataset_id', sa.Integer(), nullable=True),
    sa.Column('jobref_simulator_id', sa.Integer(), nullable=True),
    sa.ForeignKeyConstraint(['jobref_parca_dataset_id'], ['parca_dataset.id'], ),
    sa.ForeignKeyConstraint(['jobref_simulation_id'], ['simulation.id'], ),
    sa.ForeignKeyConstraint(['jobref_simulator_id'], ['simulator.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_hpcrun_jobref_parca_dataset_id'), 'hpcrun', ['jobref_parca_dataset_id'], unique=False)
    op.create_index(op.f('ix_hpcrun_jobref_simulation_id'), 'hpcrun', ['jobref_simulation_id'], unique=False)
    op.create_index(op.f('ix_hpcrun_jobref_simulator_id'), 'hpcrun', ['jobref_simulator_id'], unique=False)
    op.create_table('worker_event',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('created_at', sa.DateTime(), server_default=sa.text('now()'), nullable=False),
    sa.Column('sequence_number', sa.Integer(), nullable=False),
    sa.Column('sim_data', postgresql.JSONB(astext_type=sa.Text()), nullable=False),
    sa.Column('global_time', sa.Float(), nullable=True),
    sa.Column('error_message', sa.String(), nullable=True),
    sa.Column('hpcrun_id', sa.Integer(), nullable=False),
    sa.ForeignKeyConstraint(['hpcrun_id'], ['hpcrun.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_worker_event_hpcrun_id'), 'worker_event', ['hpcrun_id'], unique=False)
    op.create_index(op.f('ix_worker_event_sequence_number'), 'worker_event', ['sequence_number'], unique=False)
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index(op.f('ix_worker_event_sequence_number'), table_name='worker_event')
    op.drop_index(op.f('ix_worker_event_hpcrun_id'), table_name='worker_event')
    op.drop_table('worker_event')
    op.drop_index(op.f('ix_hpcrun_jobref_simulator_id'), table_name='hpcrun')
    op.drop_index(op.f('ix_hpcrun_jobref_simulation_id'), table_name='hpcrun')
    op.drop_index(op.f('ix_hpcrun_jobref_parca_dataset_id'), table_name='hpcrun')
    op.drop_table('hpcrun')
    op.drop_index(op.f('ix_simulation_simulator_id'), table_name='simulation')
    op.drop_index(op.f('ix_simulation_parca_dataset_id'), table_name='simulation')
    op.drop_table('simulation')
    op.drop_index(op.f('ix_parca_dataset_simulator_id'), table_name='parca_dataset')
    op.drop_table('parca_dataset')
    op.drop_table('simulator')
    # ### end Alembic commands ###
